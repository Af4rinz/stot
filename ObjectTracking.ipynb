{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\tableofcontents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project deals with the problem of object tracking in a static-background environment. The goal is to find and track objects in a video sequence. The methods used are based on the work of Nummiaro et al. \\cite{nummiaro2002}, where applying colour distributions, make the model more robust to brief and partial occlusion, rotation, and scale changes, especially efficient and useful in the case of single-target tracking.\n",
    "The videos used in this project are from the MOT17 challenge dataset \\cite{mot17}, available [here](https://motchallenge.net/data/MOT17/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# general\n",
    "from src.utils import *\n",
    "import os\n",
    "import time\n",
    "# computation and vision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['F_PG1_Subject_2_L', 'F_CP_1_Subject_1']\n",
    "names = ['MOT17-09-DPM-raw']\n",
    "# extensions = {'F_PG1_Subject_2_L': '.avi', 'F_CP_1_Subject_1': '.mp4'}\n",
    "extensions = {'MOT17-09-DPM-raw': '.mp4'}\n",
    "videos = {}\n",
    "for name in names:\n",
    "    videos[name] = load_video('./MOT/'+name+extensions[name], show=False, f=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle-Filter Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method, based on the work *An Adaptive Colour-Based Particle Filter* \\cite{nummiaro2002}, and follows a top-down approach, where it generates object hypotheses and attempts to verify them with the data. Using the colour distributions, this method only attempts to match only objects that have a similar histogram and build on top of particle filtering.\n",
    "\n",
    "## Definition\n",
    "Particle filtering tracks the state of an object described by a vector $X_t$ while an observation vector $Z_t$ keeps track of all observations up to time $t$. These filters are often used for non-Gaussian posterior density $p(X_t|Z_t)$ and observation density $p(z_t|X_t)$. The key idea is approximating the probability distribution by a weighted samples set $S$ where each sample denotes a hypothetical state of the object with a discrete sampling probability distribution $\\pi$.\n",
    "\n",
    "The sample set evolves by propagating each sample according to a model, then each element is weighted in terms of observation and $N$ samples are drawn by choosing a particular sample with probabily $\\pi^{(n)} = p(z_t|X_t = s_t^{(n)}).$ The mean state of an object is estimated at each time $t$ by:\n",
    "$$ E[S] = \\sum_{n=1}^{N}{\\pi^{(n)}s^{(n)}}$$\n",
    "By modelling uncertainty, the model keeps the options open and can consider multiple hypotheses and choose the closest. By keeping the less likely states in memory briefly, the model can deal with short-term occlusion.\n",
    "\n",
    "### Colour Distribution\n",
    "The colour distribution are used to provide robustness to non-rigidity, rotation, scaling, and partial occlusion. By discretizing the distributions into $m$ bins, histograms produced are produced in HSV colour space to allow for less sensitivity to illumination changes (fewer bins in the V channel). The distribution is determined inside an upright elliptic region with half axes $H_x$ and $H_y$. Smaller weights are assigned to pixels farther from the centre of the region using a weighting function.\n",
    "$$k(r) = \\left \\{ \\begin{array}{ccl}1-r^2 & r < 1 \\\\ 0 & otherwise \\end{array}\\right.$$\n",
    "where $r$ is the distance from the centre of the region.\n",
    "The colour distribution $p_y = {p_y^{(u)}}_{u=1..m}$ is defined as:\n",
    "$$p_y^{(u)} = f \\sum_{i=1}^{I}{k(\\frac{||y-x_i||}{a})\\delta[h(x_i) - u]}$$\n",
    "where $f$ is the normalization factor, $I$ is the number of pixels in region, $\\delta$ is the Kronecker delta function, and $a=\\sqrt{H_x^2+H_y^2}$.\n",
    "Considering the colour histograms $p$ and $q$, the similarity measure is defined using Bhattacharyya coefficient:\n",
    "$$\\rho[p,q] = \\sum_{u=1}^{m}{\\sqrt{p^{(u)}q^{(u)}}}$$\n",
    "and hence the Bhattacharyya distance, which updates the a priori distribution given by particle filter, is:\n",
    "$$d[p,q] = \\sqrt{1-\\rho[p,q]}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample in the distribution represents an ellipse given by $state = {x, y, \\dot{x}, \\dot{y}, H_x, H_y, \\dot{a}}$, where $(x,y)$ is the coordinate of the central point, $(H_x, H_y)$ are the half axes, $(\\dot{x}, \\dot{y})$ is the motion, and $\\dot{a}$ is the scale change.\n",
    "The sample set is then propagated using:\n",
    "$$s_t = A s_{t-1} + w_{t-1}$$\n",
    "where $A$ defines the deterministic component of the model and $w_{t-1}$ is a multivariate Gaussian random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm and Implementation\n",
    "The algorithm has four main steps following model initialization:\n",
    "1. **Select**: selects $N$ samples from set $S_{t-1}$ with probability $\\pi_{t-1}^{(n)}$.\n",
    "2. **Propagate**: propagates each sample from set $S'_{t-1}$ by the equation given above.\n",
    "3. **Observe**: observes the colour distributions using the method described.\n",
    "4. **Estimate**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload utils\n",
    "from importlib import reload\n",
    "import src.utils\n",
    "import src.ParticleFilter \n",
    "reload(src.utils)\n",
    "reload(src.ParticleFilter)\n",
    "from src.utils import *\n",
    "from src.ParticleFilter import ParticleFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 57\n",
      "84 59\n",
      "56 128\n",
      "94 123\n"
     ]
    }
   ],
   "source": [
    "name = 'MOT17-09-DPM-raw'\n",
    "sframe = 50\n",
    "eframe = 150\n",
    "p_count = 30\n",
    "get_points(videos[name][sframe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5 * (94 - 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.copy(videos[name][sframe:eframe])\n",
    "PF = ParticleFilter(frames, particle_count=p_count, init_x=77, init_y=93, init_Hx=17, init_Hy=35, out_path='./output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pf_df = pd.DataFrame(columns=['Test', 'Time', 'Particle Count'])\n",
    "# or import from file\n",
    "pf_df = pd.read_csv('./output/pf_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selection on frame 1\n",
      "x: 251, y: 89, Hx: 10, Hy: 24\n",
      "selection on frame 2\n",
      "x: 251, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 3\n",
      "x: 251, y: 90, Hx: 9, Hy: 24\n",
      "selection on frame 4\n",
      "x: 250, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 5\n",
      "x: 249, y: 91, Hx: 10, Hy: 24\n",
      "selection on frame 6\n",
      "x: 249, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 7\n",
      "x: 248, y: 91, Hx: 10, Hy: 24\n",
      "selection on frame 8\n",
      "x: 248, y: 90, Hx: 10, Hy: 23\n",
      "selection on frame 9\n",
      "x: 247, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 10\n",
      "x: 246, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 11\n",
      "x: 246, y: 89, Hx: 10, Hy: 24\n",
      "selection on frame 12\n",
      "x: 244, y: 88, Hx: 10, Hy: 24\n",
      "selection on frame 13\n",
      "x: 245, y: 89, Hx: 9, Hy: 23\n",
      "selection on frame 14\n",
      "x: 245, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 15\n",
      "x: 244, y: 89, Hx: 9, Hy: 23\n",
      "selection on frame 16\n",
      "x: 244, y: 89, Hx: 10, Hy: 24\n",
      "selection on frame 17\n",
      "x: 243, y: 89, Hx: 10, Hy: 24\n",
      "selection on frame 18\n",
      "x: 242, y: 88, Hx: 9, Hy: 23\n",
      "selection on frame 19\n",
      "x: 242, y: 88, Hx: 9, Hy: 23\n",
      "selection on frame 20\n",
      "x: 242, y: 88, Hx: 10, Hy: 24\n",
      "selection on frame 21\n",
      "x: 242, y: 88, Hx: 9, Hy: 23\n",
      "selection on frame 22\n",
      "x: 242, y: 87, Hx: 9, Hy: 23\n",
      "selection on frame 23\n",
      "x: 241, y: 87, Hx: 10, Hy: 24\n",
      "selection on frame 24\n",
      "x: 241, y: 86, Hx: 9, Hy: 23\n",
      "selection on frame 25\n",
      "x: 241, y: 88, Hx: 10, Hy: 24\n",
      "selection on frame 26\n",
      "x: 240, y: 87, Hx: 10, Hy: 23\n",
      "selection on frame 27\n",
      "x: 240, y: 90, Hx: 10, Hy: 23\n",
      "selection on frame 28\n",
      "x: 239, y: 90, Hx: 9, Hy: 23\n",
      "selection on frame 29\n",
      "x: 239, y: 88, Hx: 10, Hy: 24\n",
      "selection on frame 30\n",
      "x: 240, y: 88, Hx: 10, Hy: 24\n",
      "selection on frame 31\n",
      "x: 239, y: 88, Hx: 10, Hy: 24\n",
      "selection on frame 32\n",
      "x: 239, y: 88, Hx: 10, Hy: 24\n",
      "selection on frame 33\n",
      "x: 238, y: 88, Hx: 9, Hy: 23\n",
      "selection on frame 34\n",
      "x: 237, y: 87, Hx: 9, Hy: 23\n",
      "selection on frame 35\n",
      "x: 236, y: 88, Hx: 10, Hy: 24\n",
      "selection on frame 36\n",
      "x: 236, y: 89, Hx: 10, Hy: 24\n",
      "selection on frame 37\n",
      "x: 234, y: 90, Hx: 9, Hy: 23\n",
      "selection on frame 38\n",
      "x: 234, y: 89, Hx: 10, Hy: 24\n",
      "selection on frame 39\n",
      "x: 234, y: 89, Hx: 10, Hy: 24\n",
      "selection on frame 40\n",
      "x: 233, y: 92, Hx: 10, Hy: 24\n",
      "selection on frame 41\n",
      "x: 232, y: 90, Hx: 9, Hy: 23\n",
      "selection on frame 42\n",
      "x: 230, y: 89, Hx: 10, Hy: 24\n",
      "selection on frame 43\n",
      "x: 229, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 44\n",
      "x: 228, y: 90, Hx: 9, Hy: 23\n",
      "selection on frame 45\n",
      "x: 226, y: 92, Hx: 9, Hy: 23\n",
      "selection on frame 46\n",
      "x: 224, y: 91, Hx: 10, Hy: 24\n",
      "selection on frame 47\n",
      "x: 225, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 48\n",
      "x: 224, y: 89, Hx: 9, Hy: 23\n",
      "selection on frame 49\n",
      "x: 224, y: 88, Hx: 10, Hy: 24\n",
      "selection on frame 50\n",
      "x: 224, y: 86, Hx: 10, Hy: 24\n",
      "selection on frame 51\n",
      "x: 224, y: 86, Hx: 10, Hy: 24\n",
      "selection on frame 52\n",
      "x: 222, y: 86, Hx: 9, Hy: 23\n",
      "selection on frame 53\n",
      "x: 222, y: 85, Hx: 10, Hy: 24\n",
      "selection on frame 54\n",
      "x: 222, y: 85, Hx: 10, Hy: 24\n",
      "selection on frame 55\n",
      "x: 222, y: 83, Hx: 10, Hy: 23\n",
      "selection on frame 56\n",
      "x: 222, y: 84, Hx: 10, Hy: 24\n",
      "selection on frame 57\n",
      "x: 221, y: 84, Hx: 10, Hy: 24\n",
      "selection on frame 58\n",
      "x: 219, y: 86, Hx: 10, Hy: 24\n",
      "selection on frame 59\n",
      "x: 219, y: 87, Hx: 10, Hy: 24\n",
      "selection on frame 60\n",
      "x: 217, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 61\n",
      "x: 216, y: 91, Hx: 9, Hy: 23\n",
      "selection on frame 62\n",
      "x: 215, y: 89, Hx: 9, Hy: 23\n",
      "selection on frame 63\n",
      "x: 215, y: 88, Hx: 10, Hy: 24\n",
      "selection on frame 64\n",
      "x: 214, y: 88, Hx: 9, Hy: 23\n",
      "selection on frame 65\n",
      "x: 213, y: 89, Hx: 9, Hy: 23\n",
      "selection on frame 66\n",
      "x: 213, y: 88, Hx: 9, Hy: 23\n",
      "selection on frame 67\n",
      "x: 212, y: 88, Hx: 10, Hy: 24\n",
      "selection on frame 68\n",
      "x: 211, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 69\n",
      "x: 210, y: 91, Hx: 10, Hy: 24\n",
      "selection on frame 70\n",
      "x: 210, y: 91, Hx: 10, Hy: 24\n",
      "selection on frame 71\n",
      "x: 209, y: 92, Hx: 10, Hy: 24\n",
      "selection on frame 72\n",
      "x: 207, y: 93, Hx: 9, Hy: 23\n",
      "selection on frame 73\n",
      "x: 205, y: 93, Hx: 10, Hy: 24\n",
      "selection on frame 74\n",
      "x: 205, y: 92, Hx: 10, Hy: 24\n",
      "selection on frame 75\n",
      "x: 204, y: 92, Hx: 10, Hy: 24\n",
      "selection on frame 76\n",
      "x: 202, y: 91, Hx: 9, Hy: 23\n",
      "selection on frame 77\n",
      "x: 201, y: 91, Hx: 10, Hy: 24\n",
      "selection on frame 78\n",
      "x: 200, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 79\n",
      "x: 200, y: 88, Hx: 10, Hy: 24\n",
      "selection on frame 80\n",
      "x: 200, y: 86, Hx: 9, Hy: 23\n",
      "selection on frame 81\n",
      "x: 200, y: 86, Hx: 10, Hy: 24\n",
      "selection on frame 82\n",
      "x: 200, y: 85, Hx: 10, Hy: 24\n",
      "selection on frame 83\n",
      "x: 199, y: 84, Hx: 10, Hy: 24\n",
      "selection on frame 84\n",
      "x: 198, y: 85, Hx: 10, Hy: 24\n",
      "selection on frame 85\n",
      "x: 197, y: 85, Hx: 10, Hy: 24\n",
      "selection on frame 86\n",
      "x: 196, y: 91, Hx: 9, Hy: 23\n",
      "selection on frame 87\n",
      "x: 195, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 88\n",
      "x: 193, y: 92, Hx: 10, Hy: 24\n",
      "selection on frame 89\n",
      "x: 191, y: 91, Hx: 10, Hy: 23\n",
      "selection on frame 90\n",
      "x: 191, y: 91, Hx: 9, Hy: 23\n",
      "selection on frame 91\n",
      "x: 190, y: 90, Hx: 10, Hy: 23\n",
      "selection on frame 92\n",
      "x: 190, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 93\n",
      "x: 189, y: 90, Hx: 10, Hy: 24\n",
      "selection on frame 94\n",
      "x: 189, y: 91, Hx: 10, Hy: 24\n",
      "selection on frame 95\n",
      "x: 188, y: 92, Hx: 9, Hy: 24\n",
      "selection on frame 96\n",
      "x: 187, y: 93, Hx: 10, Hy: 24\n",
      "selection on frame 97\n",
      "x: 185, y: 92, Hx: 9, Hy: 23\n",
      "selection on frame 98\n",
      "x: 184, y: 93, Hx: 10, Hy: 24\n",
      "selection on frame 99\n",
      "x: 183, y: 93, Hx: 10, Hy: 24\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "while PF.f_idx < len(PF.frames) - 1:\n",
    "    PF.select()\n",
    "    PF.propagate()\n",
    "    PF.observe()\n",
    "    PF.estimate()\n",
    "pf_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_df.loc[len(pf_df)] = [name, pf_time, len(PF.particles)]\n",
    "pf_df.to_csv('./output/pf_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Time</th>\n",
       "      <th>Particle Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOT17-09-DPM-raw</td>\n",
       "      <td>2087.300000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOT17-09-DPM-raw</td>\n",
       "      <td>496.561201</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MOT17-09-DPM-raw</td>\n",
       "      <td>3197.979189</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Test         Time  Particle Count\n",
       "0  MOT17-09-DPM-raw  2087.300000              50\n",
       "1  MOT17-09-DPM-raw   496.561201              10\n",
       "2  MOT17-09-DPM-raw  3197.979189              80"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_output(output_name=f'{name}_{PF.particle_count}_{PF.SCALE_CHANGE_D}.mp4')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
